{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">MIS 382N: Advanced Predictive Modeling</p>\n",
    "# <p style=\"text-align: center;\">Assignment 5</p>\n",
    "## <p style=\"text-align: center;\">Total points: 50 </p>\n",
    "## <p style=\"text-align: center;\">Due: Mon, November 28</p>\n",
    "\n",
    "## <p style=\"text-align: center;\">Group: Sean Kessel & J. Dallas Griffin</p>\n",
    "\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. Please submit **only one** ipynb file from each group, and include the names of all the group members. Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Random Forest vs Boosting - Regression (15pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we will compare performance of different ensemble methods for regression problems: [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), [Gradient Boosting Regressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) (GBR), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor). Board game data set from DataQuest will be used (you can download data from Canvas: 'games.csv').\n",
    "\n",
    "1. (1) Load the data, (2) remove duplicate rows, (3) remove features of type string (object in pandas), and (4) replace missing values by mean of each column. Then, partition data into features (X) and the target label (y) for regression task. We want to predict the *average_rating*. Use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and testing: test_size=0.33, random_state=42. (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 \n",
    "#### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81312, 20)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import (RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor)\n",
    "\n",
    "games_df = pd.read_csv(\"games.csv\")\n",
    "\n",
    "games_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79463, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df = games_df.drop_duplicates()\n",
    "games_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_cols = []\n",
    "for i in range(len(games_df.dtypes)):\n",
    "    if games_df.dtypes[i] == 'O':\n",
    "        drop_cols.append(games_df.columns[i])\n",
    "games_df = games_df.drop(drop_cols,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games_df = games_df.fillna(games_df.mean())\n",
    "\n",
    "games_dfX = games_df.drop(\"average_rating\",axis=1)\n",
    "games_dfY = games_df[[\"average_rating\"]]\n",
    "X = games_dfX.as_matrix()\n",
    "Y = games_dfY.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Use a [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) to predict average_rating. Find the best parameters (including *n_estimators*) using [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Report the accuracy of your model in terms of RMSE. (4pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE:  1.02405047671\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.870301</td>\n",
       "      <td>0.971817</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.871490</td>\n",
       "      <td>0.971956</td>\n",
       "      <td>0.870658</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>0.868756</td>\n",
       "      <td>0.972166</td>\n",
       "      <td>0.104766</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.832333</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.881728</td>\n",
       "      <td>0.978587</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.881962</td>\n",
       "      <td>0.978111</td>\n",
       "      <td>0.882019</td>\n",
       "      <td>0.979033</td>\n",
       "      <td>0.881203</td>\n",
       "      <td>0.978618</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.024042</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.683000</td>\n",
       "      <td>0.059333</td>\n",
       "      <td>0.884713</td>\n",
       "      <td>0.980974</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885611</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.885385</td>\n",
       "      <td>0.981096</td>\n",
       "      <td>0.883144</td>\n",
       "      <td>0.980697</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.996000         0.026000         0.870301          0.971817   \n",
       "1       1.832333         0.059000         0.881728          0.978587   \n",
       "2       2.683000         0.059333         0.884713          0.980974   \n",
       "\n",
       "  param_n_estimators                 params  rank_test_score  \\\n",
       "0                  5   {u'n_estimators': 5}                3   \n",
       "1                 10  {u'n_estimators': 10}                2   \n",
       "2                 15  {u'n_estimators': 15}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.871490            0.971956           0.870658   \n",
       "1           0.881962            0.978111           0.882019   \n",
       "2           0.885611            0.981130           0.885385   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.971329           0.868756            0.972166      0.104766   \n",
       "1            0.979033           0.881203            0.978618      0.004110   \n",
       "2            0.981096           0.883144            0.980697      0.011431   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.007789        0.001144         0.000356  \n",
       "1        0.024042        0.000372         0.000377  \n",
       "2        0.001247        0.001113         0.000197  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "RandFor = RandomForestRegressor()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)]}\n",
    "\n",
    "clf = GridSearchCV(RandFor, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Random Forest RMSE: \", np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "Use [Gradient Boosting Regressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) (GBR), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor) for predicting the targets. Again, find the best parameters (including *n_estimators,* and* learning_rate*), and report corresponding RMSE for each algorithm. (8pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost RMSE:  1.26376339821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.164333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.558891</td>\n",
       "      <td>0.559193</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557174</td>\n",
       "      <td>0.559116</td>\n",
       "      <td>0.561560</td>\n",
       "      <td>0.559040</td>\n",
       "      <td>0.557938</td>\n",
       "      <td>0.559424</td>\n",
       "      <td>0.006848</td>\n",
       "      <td>4.715390e-04</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.276333</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.757417</td>\n",
       "      <td>0.757920</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755931</td>\n",
       "      <td>0.757992</td>\n",
       "      <td>0.760027</td>\n",
       "      <td>0.757267</td>\n",
       "      <td>0.756294</td>\n",
       "      <td>0.758502</td>\n",
       "      <td>0.006549</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.000507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.829294</td>\n",
       "      <td>0.829973</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828369</td>\n",
       "      <td>0.830177</td>\n",
       "      <td>0.831583</td>\n",
       "      <td>0.829155</td>\n",
       "      <td>0.827931</td>\n",
       "      <td>0.830587</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175667</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.081725</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.081346</td>\n",
       "      <td>0.081793</td>\n",
       "      <td>0.082154</td>\n",
       "      <td>0.081724</td>\n",
       "      <td>0.081675</td>\n",
       "      <td>0.081883</td>\n",
       "      <td>0.018080</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.282333</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.155692</td>\n",
       "      <td>0.155781</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.155020</td>\n",
       "      <td>0.155766</td>\n",
       "      <td>0.156517</td>\n",
       "      <td>0.155639</td>\n",
       "      <td>0.155539</td>\n",
       "      <td>0.155937</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.409333</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.222593</td>\n",
       "      <td>0.222702</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.221690</td>\n",
       "      <td>0.222686</td>\n",
       "      <td>0.223760</td>\n",
       "      <td>0.222492</td>\n",
       "      <td>0.222327</td>\n",
       "      <td>0.222928</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.154333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.008509</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.283667</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.016883</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.016954</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>0.016965</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.418667</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>0.025296</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.025084</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>0.025257</td>\n",
       "      <td>0.025322</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.164333         0.003333         0.558891          0.559193   \n",
       "1       0.276333         0.005000         0.757417          0.757920   \n",
       "2       0.390000         0.006000         0.829294          0.829973   \n",
       "3       0.175667         0.003333         0.081725          0.081800   \n",
       "4       0.282333         0.005000         0.155692          0.155781   \n",
       "5       0.409333         0.007333         0.222593          0.222702   \n",
       "6       0.154333         0.003333         0.008453          0.008516   \n",
       "7       0.283667         0.004667         0.016883          0.016948   \n",
       "8       0.418667         0.007000         0.025230          0.025296   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "0                 0.1                  5   \n",
       "1                 0.1                 10   \n",
       "2                 0.1                 15   \n",
       "3                0.01                  5   \n",
       "4                0.01                 10   \n",
       "5                0.01                 15   \n",
       "6               0.001                  5   \n",
       "7               0.001                 10   \n",
       "8               0.001                 15   \n",
       "\n",
       "                                           params  rank_test_score  \\\n",
       "0     {u'n_estimators': 5, u'learning_rate': 0.1}                3   \n",
       "1    {u'n_estimators': 10, u'learning_rate': 0.1}                2   \n",
       "2    {u'n_estimators': 15, u'learning_rate': 0.1}                1   \n",
       "3    {u'n_estimators': 5, u'learning_rate': 0.01}                6   \n",
       "4   {u'n_estimators': 10, u'learning_rate': 0.01}                5   \n",
       "5   {u'n_estimators': 15, u'learning_rate': 0.01}                4   \n",
       "6   {u'n_estimators': 5, u'learning_rate': 0.001}                9   \n",
       "7  {u'n_estimators': 10, u'learning_rate': 0.001}                8   \n",
       "8  {u'n_estimators': 15, u'learning_rate': 0.001}                7   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.557174            0.559116           0.561560   \n",
       "1           0.755931            0.757992           0.760027   \n",
       "2           0.828369            0.830177           0.831583   \n",
       "3           0.081346            0.081793           0.082154   \n",
       "4           0.155020            0.155766           0.156517   \n",
       "5           0.221690            0.222686           0.223760   \n",
       "6           0.008379            0.008516           0.008476   \n",
       "7           0.016773            0.016947           0.016954   \n",
       "8           0.025084            0.025294           0.025348   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.559040           0.557938            0.559424      0.006848   \n",
       "1            0.757267           0.756294            0.758502      0.006549   \n",
       "2            0.829155           0.827931            0.830587      0.008287   \n",
       "3            0.081724           0.081675            0.081883      0.018080   \n",
       "4            0.155639           0.155539            0.155937      0.006342   \n",
       "5            0.222492           0.222327            0.222928      0.017613   \n",
       "6            0.008509           0.008503            0.008525      0.003300   \n",
       "7            0.016932           0.016922            0.016965      0.001886   \n",
       "8            0.025272           0.025257            0.025322      0.010530   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0    4.715390e-04        0.001913         0.000166  \n",
       "1    1.123916e-07        0.001851         0.000507  \n",
       "2    1.123916e-07        0.001628         0.000602  \n",
       "3    4.713704e-04        0.000332         0.000065  \n",
       "4    1.123916e-07        0.000621         0.000122  \n",
       "5    4.714827e-04        0.000866         0.000178  \n",
       "6    4.713704e-04        0.000053         0.000007  \n",
       "7    4.713142e-04        0.000079         0.000014  \n",
       "8    1.123916e-07        0.000109         0.000020  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Gradient Boost\n",
    "\n",
    "GradBoost = GradientBoostingRegressor()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)],\"learning_rate\":[10**(0-i-1) for i in range(3)]}\n",
    "\n",
    "clf = GridSearchCV(GradBoost, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Gradient Boost RMSE: \", np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost RMSE:  1.15370347462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.322667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.854804</td>\n",
       "      <td>0.855398</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.853918</td>\n",
       "      <td>0.855063</td>\n",
       "      <td>0.856863</td>\n",
       "      <td>0.854714</td>\n",
       "      <td>0.853630</td>\n",
       "      <td>0.856416</td>\n",
       "      <td>0.035612</td>\n",
       "      <td>1.699768e-03</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.633667</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.856185</td>\n",
       "      <td>0.856651</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.856918</td>\n",
       "      <td>0.857817</td>\n",
       "      <td>0.857710</td>\n",
       "      <td>0.855478</td>\n",
       "      <td>0.853928</td>\n",
       "      <td>0.856659</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.000955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.016333</td>\n",
       "      <td>0.858075</td>\n",
       "      <td>0.858591</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857844</td>\n",
       "      <td>0.858907</td>\n",
       "      <td>0.860829</td>\n",
       "      <td>0.858641</td>\n",
       "      <td>0.855551</td>\n",
       "      <td>0.858226</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307667</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.854855</td>\n",
       "      <td>0.855412</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.854113</td>\n",
       "      <td>0.855177</td>\n",
       "      <td>0.856795</td>\n",
       "      <td>0.854698</td>\n",
       "      <td>0.853658</td>\n",
       "      <td>0.856360</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.000699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.855384</td>\n",
       "      <td>0.855586</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855443</td>\n",
       "      <td>0.855684</td>\n",
       "      <td>0.856985</td>\n",
       "      <td>0.854702</td>\n",
       "      <td>0.853724</td>\n",
       "      <td>0.856373</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.926333</td>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.855376</td>\n",
       "      <td>0.855681</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.855506</td>\n",
       "      <td>0.855756</td>\n",
       "      <td>0.856923</td>\n",
       "      <td>0.854840</td>\n",
       "      <td>0.853698</td>\n",
       "      <td>0.856447</td>\n",
       "      <td>0.014885</td>\n",
       "      <td>9.427969e-04</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.299333</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.855382</td>\n",
       "      <td>0.855572</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.855628</td>\n",
       "      <td>0.855602</td>\n",
       "      <td>0.856866</td>\n",
       "      <td>0.854693</td>\n",
       "      <td>0.853653</td>\n",
       "      <td>0.856421</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.855415</td>\n",
       "      <td>0.855655</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.855775</td>\n",
       "      <td>0.855850</td>\n",
       "      <td>0.856850</td>\n",
       "      <td>0.854729</td>\n",
       "      <td>0.853620</td>\n",
       "      <td>0.856388</td>\n",
       "      <td>0.011225</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.145667</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.855379</td>\n",
       "      <td>0.855616</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.855590</td>\n",
       "      <td>0.855632</td>\n",
       "      <td>0.856867</td>\n",
       "      <td>0.854809</td>\n",
       "      <td>0.853680</td>\n",
       "      <td>0.856407</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>7.071005e-03</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.000652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.322667         0.006667         0.854804          0.855398   \n",
       "1       0.633667         0.011333         0.856185          0.856651   \n",
       "2       0.925000         0.016333         0.858075          0.858591   \n",
       "3       0.307667         0.005667         0.854855          0.855412   \n",
       "4       0.607000         0.011333         0.855384          0.855586   \n",
       "5       0.926333         0.017667         0.855376          0.855681   \n",
       "6       0.299333         0.006000         0.855382          0.855572   \n",
       "7       0.608000         0.011000         0.855415          0.855655   \n",
       "8       1.145667         0.022000         0.855379          0.855616   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "0                 0.1                  5   \n",
       "1                 0.1                 10   \n",
       "2                 0.1                 15   \n",
       "3                0.01                  5   \n",
       "4                0.01                 10   \n",
       "5                0.01                 15   \n",
       "6               0.001                  5   \n",
       "7               0.001                 10   \n",
       "8               0.001                 15   \n",
       "\n",
       "                                           params  rank_test_score  \\\n",
       "0     {u'n_estimators': 5, u'learning_rate': 0.1}                9   \n",
       "1    {u'n_estimators': 10, u'learning_rate': 0.1}                2   \n",
       "2    {u'n_estimators': 15, u'learning_rate': 0.1}                1   \n",
       "3    {u'n_estimators': 5, u'learning_rate': 0.01}                8   \n",
       "4   {u'n_estimators': 10, u'learning_rate': 0.01}                4   \n",
       "5   {u'n_estimators': 15, u'learning_rate': 0.01}                7   \n",
       "6   {u'n_estimators': 5, u'learning_rate': 0.001}                5   \n",
       "7  {u'n_estimators': 10, u'learning_rate': 0.001}                3   \n",
       "8  {u'n_estimators': 15, u'learning_rate': 0.001}                6   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.853918            0.855063           0.856863   \n",
       "1           0.856918            0.857817           0.857710   \n",
       "2           0.857844            0.858907           0.860829   \n",
       "3           0.854113            0.855177           0.856795   \n",
       "4           0.855443            0.855684           0.856985   \n",
       "5           0.855506            0.855756           0.856923   \n",
       "6           0.855628            0.855602           0.856866   \n",
       "7           0.855775            0.855850           0.856850   \n",
       "8           0.855590            0.855632           0.856867   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.854714           0.853630            0.856416      0.035612   \n",
       "1            0.855478           0.853928            0.856659      0.018732   \n",
       "2            0.858641           0.855551            0.858226      0.002160   \n",
       "3            0.854698           0.853658            0.856360      0.002494   \n",
       "4            0.854702           0.853724            0.856373      0.009092   \n",
       "5            0.854840           0.853698            0.856447      0.014885   \n",
       "6            0.854693           0.853653            0.856421      0.004643   \n",
       "7            0.854729           0.853620            0.856388      0.011225   \n",
       "8            0.854809           0.853680            0.856407      0.276618   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0    1.699768e-03        0.001461         0.000734  \n",
       "1    4.714266e-04        0.001629         0.000955  \n",
       "2    4.713704e-04        0.002161         0.000281  \n",
       "3    4.714266e-04        0.001384         0.000699  \n",
       "4    4.713704e-04        0.001332         0.000685  \n",
       "5    9.427969e-04        0.001320         0.000658  \n",
       "6    1.123916e-07        0.001323         0.000706  \n",
       "7    0.000000e+00        0.001343         0.000691  \n",
       "8    7.071005e-03        0.001310         0.000652  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## AdaBoost\n",
    "\n",
    "AdaBoost = AdaBoostRegressor()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)],\"learning_rate\":[10**(0-i-1) for i in range(3)]}\n",
    "\n",
    "clf = GridSearchCV(AdaBoost, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"AdaBoost RMSE: \", np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "\n",
    "Which model did you expect to be more accurate in predicting the targets? Why? Did your observation match this expectation? (2pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expected Gradient Boost to perform the best, though in actuality Random Forest has the lowest out of sample RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Random Forest vs Boosting - Classification (15 pts)\n",
    "In this question, we will compare performance of different ensemble methods for classification problems: [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) (GBDT), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier). [Spam Classification Data](https://archive.ics.uci.edu/ml/datasets/Spambase) of UCI will be used (you can download data from Canvas: 'spam_uci.csv'). Don't worry about column names. The last column represents target label, 1 if spam and zero otherwise.\n",
    "\n",
    "1. Load the data and partition it into features (X) and the target label (y) for classification task. Then, use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and testing: test_size=0.33, random_state=42. (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score)\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier)\n",
    "\n",
    "spam_df = pd.read_csv(\"spam_uci.csv\")\n",
    "\n",
    "X = spam_df.drop(\"57\",axis=1)\n",
    "y = spam_df[\"57\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Use a [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to classify whether an email is spam. Find the best parameters (including *n_estimators* and *criterion*) using [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Report your testing accuracy ([accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)) and [roc_auc_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score). You will need [predict_proba](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba) for roc_auc_score. (4pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score:  1.0\n",
      "Random Forest Roc_auc Score:  1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039333</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.995782</td>\n",
       "      <td>0.999513</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.999513</td>\n",
       "      <td>0.993184</td>\n",
       "      <td>0.999027</td>\n",
       "      <td>0.025224</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.999027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.039333         0.004000         0.995782          0.999513   \n",
       "1       0.039333         0.006667         0.999027          1.000000   \n",
       "2       0.067000         0.011000         0.999676          1.000000   \n",
       "\n",
       "  param_n_estimators                 params  rank_test_score  \\\n",
       "0                  5   {u'n_estimators': 5}                3   \n",
       "1                 10  {u'n_estimators': 10}                2   \n",
       "2                 15  {u'n_estimators': 15}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.996109                 1.0           0.998053   \n",
       "1           0.999027                 1.0           0.998053   \n",
       "2           1.000000                 1.0           0.999026   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.999513           0.993184            0.999027      0.025224   \n",
       "1            1.000000           1.000000            1.000000      0.001886   \n",
       "2            1.000000           1.000000            1.000000      0.003266   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000817        0.002001         0.000397  \n",
       "1        0.000471        0.000795         0.000000  \n",
       "2        0.000000        0.000459         0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "RandFor = RandomForestClassifier()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)]}\n",
    "\n",
    "clf = GridSearchCV(RandFor, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba)[1].as_matrix()\n",
    "\n",
    "print \"Random Forest Accuracy Score: \", accuracy_score(y_test,y_pred)\n",
    "print \"Random Forest Roc_auc Score: \", roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "Use [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) (GBDT), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier) for the spam classification problem. Again, find the best parameters (including *n_estimators, learning_rate,* and *max_depth (GBDT only)*), and report corresponding accuracy_score and roc_auc_score on the test data for each algorithm. (8pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Decision Tree Accuracy Score:  0.998683344305\n",
      "Gradient Boosting Decision Tree Roc_auc Score:  0.998871331828\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1, u'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.160164e-03</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1, u'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1, u'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01, u...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>9.426845e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01, u...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>1.699659e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01, u...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.022333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>8.165347e-04</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>8.165347e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.025333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>9.428531e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.018000         0.001333         1.000000          1.000000   \n",
       "1        0.018000         0.000667         1.000000          1.000000   \n",
       "2        0.024333         0.001000         1.000000          1.000000   \n",
       "3        0.013333         0.000667         1.000000          1.000000   \n",
       "4        0.018333         0.001000         1.000000          1.000000   \n",
       "5        0.023333         0.000667         1.000000          1.000000   \n",
       "6        0.012000         0.000667         1.000000          1.000000   \n",
       "7        0.017333         0.001000         1.000000          1.000000   \n",
       "8        0.023333         0.000667         1.000000          1.000000   \n",
       "9        0.012333         0.000667         0.617132          0.617132   \n",
       "10       0.017667         0.000667         0.617132          0.617132   \n",
       "11       0.023333         0.000667         0.617132          0.617132   \n",
       "12       0.012333         0.000667         0.617132          0.617132   \n",
       "13       0.020667         0.001000         0.617132          0.617132   \n",
       "14       0.023000         0.000667         0.617132          0.617132   \n",
       "15       0.012333         0.000333         0.617132          0.617132   \n",
       "16       0.017667         0.001333         0.617132          0.617132   \n",
       "17       0.022333         0.000333         0.617132          0.617132   \n",
       "18       0.011667         0.000667         0.617132          0.617132   \n",
       "19       0.018000         0.000667         0.617132          0.617132   \n",
       "20       0.023000         0.000667         0.617132          0.617132   \n",
       "21       0.012333         0.000667         0.617132          0.617132   \n",
       "22       0.018000         0.000667         0.617132          0.617132   \n",
       "23       0.022667         0.001000         0.617132          0.617132   \n",
       "24       0.012333         0.000667         0.617132          0.617132   \n",
       "25       0.018000         0.000667         0.617132          0.617132   \n",
       "26       0.025333         0.000667         0.617132          0.617132   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                  0.1               3                  5   \n",
       "1                  0.1               3                 10   \n",
       "2                  0.1               3                 15   \n",
       "3                  0.1               5                  5   \n",
       "4                  0.1               5                 10   \n",
       "5                  0.1               5                 15   \n",
       "6                  0.1               7                  5   \n",
       "7                  0.1               7                 10   \n",
       "8                  0.1               7                 15   \n",
       "9                 0.01               3                  5   \n",
       "10                0.01               3                 10   \n",
       "11                0.01               3                 15   \n",
       "12                0.01               5                  5   \n",
       "13                0.01               5                 10   \n",
       "14                0.01               5                 15   \n",
       "15                0.01               7                  5   \n",
       "16                0.01               7                 10   \n",
       "17                0.01               7                 15   \n",
       "18               0.001               3                  5   \n",
       "19               0.001               3                 10   \n",
       "20               0.001               3                 15   \n",
       "21               0.001               5                  5   \n",
       "22               0.001               5                 10   \n",
       "23               0.001               5                 15   \n",
       "24               0.001               7                  5   \n",
       "25               0.001               7                 10   \n",
       "26               0.001               7                 15   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "0   {u'n_estimators': 5, u'learning_rate': 0.1, u'...                1   \n",
       "1   {u'n_estimators': 10, u'learning_rate': 0.1, u...                1   \n",
       "2   {u'n_estimators': 15, u'learning_rate': 0.1, u...                1   \n",
       "3   {u'n_estimators': 5, u'learning_rate': 0.1, u'...                1   \n",
       "4   {u'n_estimators': 10, u'learning_rate': 0.1, u...                1   \n",
       "5   {u'n_estimators': 15, u'learning_rate': 0.1, u...                1   \n",
       "6   {u'n_estimators': 5, u'learning_rate': 0.1, u'...                1   \n",
       "7   {u'n_estimators': 10, u'learning_rate': 0.1, u...                1   \n",
       "8   {u'n_estimators': 15, u'learning_rate': 0.1, u...                1   \n",
       "9   {u'n_estimators': 5, u'learning_rate': 0.01, u...               10   \n",
       "10  {u'n_estimators': 10, u'learning_rate': 0.01, ...               10   \n",
       "11  {u'n_estimators': 15, u'learning_rate': 0.01, ...               10   \n",
       "12  {u'n_estimators': 5, u'learning_rate': 0.01, u...               10   \n",
       "13  {u'n_estimators': 10, u'learning_rate': 0.01, ...               10   \n",
       "14  {u'n_estimators': 15, u'learning_rate': 0.01, ...               10   \n",
       "15  {u'n_estimators': 5, u'learning_rate': 0.01, u...               10   \n",
       "16  {u'n_estimators': 10, u'learning_rate': 0.01, ...               10   \n",
       "17  {u'n_estimators': 15, u'learning_rate': 0.01, ...               10   \n",
       "18  {u'n_estimators': 5, u'learning_rate': 0.001, ...               10   \n",
       "19  {u'n_estimators': 10, u'learning_rate': 0.001,...               10   \n",
       "20  {u'n_estimators': 15, u'learning_rate': 0.001,...               10   \n",
       "21  {u'n_estimators': 5, u'learning_rate': 0.001, ...               10   \n",
       "22  {u'n_estimators': 10, u'learning_rate': 0.001,...               10   \n",
       "23  {u'n_estimators': 15, u'learning_rate': 0.001,...               10   \n",
       "24  {u'n_estimators': 5, u'learning_rate': 0.001, ...               10   \n",
       "25  {u'n_estimators': 10, u'learning_rate': 0.001,...               10   \n",
       "26  {u'n_estimators': 15, u'learning_rate': 0.001,...               10   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0            1.000000            1.000000           1.000000   \n",
       "1            1.000000            1.000000           1.000000   \n",
       "2            1.000000            1.000000           1.000000   \n",
       "3            1.000000            1.000000           1.000000   \n",
       "4            1.000000            1.000000           1.000000   \n",
       "5            1.000000            1.000000           1.000000   \n",
       "6            1.000000            1.000000           1.000000   \n",
       "7            1.000000            1.000000           1.000000   \n",
       "8            1.000000            1.000000           1.000000   \n",
       "9            0.616732            0.617332           0.617332   \n",
       "10           0.616732            0.617332           0.617332   \n",
       "11           0.616732            0.617332           0.617332   \n",
       "12           0.616732            0.617332           0.617332   \n",
       "13           0.616732            0.617332           0.617332   \n",
       "14           0.616732            0.617332           0.617332   \n",
       "15           0.616732            0.617332           0.617332   \n",
       "16           0.616732            0.617332           0.617332   \n",
       "17           0.616732            0.617332           0.617332   \n",
       "18           0.616732            0.617332           0.617332   \n",
       "19           0.616732            0.617332           0.617332   \n",
       "20           0.616732            0.617332           0.617332   \n",
       "21           0.616732            0.617332           0.617332   \n",
       "22           0.616732            0.617332           0.617332   \n",
       "23           0.616732            0.617332           0.617332   \n",
       "24           0.616732            0.617332           0.617332   \n",
       "25           0.616732            0.617332           0.617332   \n",
       "26           0.616732            0.617332           0.617332   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0             1.000000           1.000000            1.000000  2.160164e-03   \n",
       "1             1.000000           1.000000            1.000000  1.123916e-07   \n",
       "2             1.000000           1.000000            1.000000  4.713142e-04   \n",
       "3             1.000000           1.000000            1.000000  4.713704e-04   \n",
       "4             1.000000           1.000000            1.000000  4.713142e-04   \n",
       "5             1.000000           1.000000            1.000000  4.714827e-04   \n",
       "6             1.000000           1.000000            1.000000  1.123916e-07   \n",
       "7             1.000000           1.000000            1.000000  4.713704e-04   \n",
       "8             1.000000           1.000000            1.000000  4.714827e-04   \n",
       "9             0.617032           0.617332            0.617032  4.714266e-04   \n",
       "10            0.617032           0.617332            0.617032  9.426845e-04   \n",
       "11            0.617032           0.617332            0.617032  4.713704e-04   \n",
       "12            0.617032           0.617332            0.617032  4.714266e-04   \n",
       "13            0.617032           0.617332            0.617032  1.699659e-03   \n",
       "14            0.617032           0.617332            0.617032  0.000000e+00   \n",
       "15            0.617032           0.617332            0.617032  4.714266e-04   \n",
       "16            0.617032           0.617332            0.617032  4.713142e-04   \n",
       "17            0.617032           0.617332            0.617032  4.713704e-04   \n",
       "18            0.617032           0.617332            0.617032  4.714266e-04   \n",
       "19            0.617032           0.617332            0.617032  8.165347e-04   \n",
       "20            0.617032           0.617332            0.617032  0.000000e+00   \n",
       "21            0.617032           0.617332            0.617032  4.714266e-04   \n",
       "22            0.617032           0.617332            0.617032  8.165347e-04   \n",
       "23            0.617032           0.617332            0.617032  4.713704e-04   \n",
       "24            0.617032           0.617332            0.617032  4.714266e-04   \n",
       "25            0.617032           0.617332            0.617032  1.123916e-07   \n",
       "26            0.617032           0.617332            0.617032  9.428531e-04   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0     4.714827e-04        0.000000         0.000000  \n",
       "1     4.714266e-04        0.000000         0.000000  \n",
       "2     1.123916e-07        0.000000         0.000000  \n",
       "3     4.714266e-04        0.000000         0.000000  \n",
       "4     1.123916e-07        0.000000         0.000000  \n",
       "5     4.713704e-04        0.000000         0.000000  \n",
       "6     4.713704e-04        0.000000         0.000000  \n",
       "7     1.123916e-07        0.000000         0.000000  \n",
       "8     4.713704e-04        0.000000         0.000000  \n",
       "9     4.714266e-04        0.000283         0.000142  \n",
       "10    4.714266e-04        0.000283         0.000142  \n",
       "11    4.713704e-04        0.000283         0.000142  \n",
       "12    4.714266e-04        0.000283         0.000142  \n",
       "13    0.000000e+00        0.000283         0.000142  \n",
       "14    4.714266e-04        0.000283         0.000142  \n",
       "15    4.713704e-04        0.000283         0.000142  \n",
       "16    4.713142e-04        0.000283         0.000142  \n",
       "17    4.713704e-04        0.000283         0.000142  \n",
       "18    4.714266e-04        0.000283         0.000142  \n",
       "19    4.714827e-04        0.000283         0.000142  \n",
       "20    4.713704e-04        0.000283         0.000142  \n",
       "21    4.713704e-04        0.000283         0.000142  \n",
       "22    4.713704e-04        0.000283         0.000142  \n",
       "23    1.123916e-07        0.000283         0.000142  \n",
       "24    4.714266e-04        0.000283         0.000142  \n",
       "25    4.714266e-04        0.000283         0.000142  \n",
       "26    4.713704e-04        0.000283         0.000142  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Gradient Boost\n",
    "\n",
    "GradBoost = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)],\"learning_rate\":[10**(0-i-1) for i in range(3)],\"max_depth\":[3,5,7]}\n",
    "\n",
    "clf = GridSearchCV(GradBoost, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba)[1].as_matrix()\n",
    "\n",
    "print \"Gradient Boosting Decision Tree Accuracy Score: \", accuracy_score(y_test,y_pred)\n",
    "print \"Gradient Boosting Decision Tree Roc_auc Score: \", roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting Accuracy Score:  0.998683344305\n",
      "AdaBoosting Roc_auc Score:  0.998871331828\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.160237e-03</td>\n",
       "      <td>9.428531e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.885594e-03</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009667</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.013000         0.001667              1.0               1.0   \n",
       "1       0.011333         0.001000              1.0               1.0   \n",
       "2       0.009333         0.001000              1.0               1.0   \n",
       "3       0.009667         0.001000              1.0               1.0   \n",
       "4       0.009333         0.000667              1.0               1.0   \n",
       "5       0.008333         0.000667              1.0               1.0   \n",
       "6       0.008333         0.000333              1.0               1.0   \n",
       "7       0.008000         0.001000              1.0               1.0   \n",
       "8       0.008667         0.000667              1.0               1.0   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "0                 0.1                  5   \n",
       "1                 0.1                 10   \n",
       "2                 0.1                 15   \n",
       "3                0.01                  5   \n",
       "4                0.01                 10   \n",
       "5                0.01                 15   \n",
       "6               0.001                  5   \n",
       "7               0.001                 10   \n",
       "8               0.001                 15   \n",
       "\n",
       "                                           params  rank_test_score  \\\n",
       "0     {u'n_estimators': 5, u'learning_rate': 0.1}                1   \n",
       "1    {u'n_estimators': 10, u'learning_rate': 0.1}                1   \n",
       "2    {u'n_estimators': 15, u'learning_rate': 0.1}                1   \n",
       "3    {u'n_estimators': 5, u'learning_rate': 0.01}                1   \n",
       "4   {u'n_estimators': 10, u'learning_rate': 0.01}                1   \n",
       "5   {u'n_estimators': 15, u'learning_rate': 0.01}                1   \n",
       "6   {u'n_estimators': 5, u'learning_rate': 0.001}                1   \n",
       "7  {u'n_estimators': 10, u'learning_rate': 0.001}                1   \n",
       "8  {u'n_estimators': 15, u'learning_rate': 0.001}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0                1.0                 1.0                1.0   \n",
       "1                1.0                 1.0                1.0   \n",
       "2                1.0                 1.0                1.0   \n",
       "3                1.0                 1.0                1.0   \n",
       "4                1.0                 1.0                1.0   \n",
       "5                1.0                 1.0                1.0   \n",
       "6                1.0                 1.0                1.0   \n",
       "7                1.0                 1.0                1.0   \n",
       "8                1.0                 1.0                1.0   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0                 1.0                1.0                 1.0  2.160237e-03   \n",
       "1                 1.0                1.0                 1.0  1.885594e-03   \n",
       "2                 1.0                1.0                 1.0  4.714827e-04   \n",
       "3                 1.0                1.0                 1.0  4.713704e-04   \n",
       "4                 1.0                1.0                 1.0  4.713704e-04   \n",
       "5                 1.0                1.0                 1.0  4.714266e-04   \n",
       "6                 1.0                1.0                 1.0  4.714266e-04   \n",
       "7                 1.0                1.0                 1.0  1.123916e-07   \n",
       "8                 1.0                1.0                 1.0  4.714266e-04   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0    9.428531e-04             0.0              0.0  \n",
       "1    1.123916e-07             0.0              0.0  \n",
       "2    0.000000e+00             0.0              0.0  \n",
       "3    1.123916e-07             0.0              0.0  \n",
       "4    4.713704e-04             0.0              0.0  \n",
       "5    4.714266e-04             0.0              0.0  \n",
       "6    4.714827e-04             0.0              0.0  \n",
       "7    1.123916e-07             0.0              0.0  \n",
       "8    4.713704e-04             0.0              0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## AdaBoost\n",
    "\n",
    "AdaBoost = AdaBoostClassifier()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)],\"learning_rate\":[10**(0-i-1) for i in range(3)]}\n",
    "\n",
    "clf = GridSearchCV(AdaBoost, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba)[1].as_matrix()\n",
    "\n",
    "print \"AdaBoosting Accuracy Score: \", accuracy_score(y_test,y_pred)\n",
    "print \"AdaBoosting Roc_auc Score: \", roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "\n",
    "Point out one advantage and one disadvantage of Random Forest compared to GBDT (2pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantage: Random Forest can work in parallel as how one tree is built does not influence how another tree gets built. This makes it more scalable, and if the data vastly expands, Random Forest could be run on multiple machines. Also its conceptually a simpler model, making it easier to explain.\n",
    "\n",
    "Disadvantage: Random Forest is suceptable to outliers, and more trees can be formed from unimportant features (as they're chosen at random). The gradient boost decision tree, on the other hand, is robust towards outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 3 - Matrix Factorization for Rating Prediction (20pts)\n",
    "\n",
    "The movielens dataset contains 1 million movie ratings from several thousand users. We will be using *k*-rank matrix factorization to estimate this dataset as the product $X=UV^T$, where *U* and *V* have only $k$ columns.\n",
    "\n",
    "1) You can download the movielens 1M dataset from https://datahub.io/dataset/movielens, but for this problem use the data available on Canvas. It has been split into training and test sets, and converted to matrix format where the rows correspond to users and the columns to movies. Note that most of the entries are NaNs, indicating that these ratings are missing. An extra file, lens1m_361M_titles.csv, has been added so you can check out specific movies if you're curious.\n",
    "\n",
    "2) Scikit-learn is a little behind for recommender systems, and doesn't have any method to factorize matrices with missing data. Which means you get to code it! Slide 22 of the 'apa large scale learning' lecture notes has the equations for stochastic gradient descent on *U* and *V*. You will have to:\n",
    "* Set up initial guesses for the *U* and *V* matrices. I suggest small random values.\n",
    "* Find a suitable learning rate for the descent. A learning rate that is too large will probably blow up, like in HW3 problem 1.\n",
    "* Come up with a stopping policy\n",
    "* Code the descent algorithm (5 pts)\n",
    "\n",
    "3) Using your SGD algorithm, apply 2-rank matrix factorization on the filled training matrix. Calculate the RMSE of this model on the training data and on the test data (separately). The optimal score on the training data is around .86 RMSE; your version of gradient descent must go at least below .91 RMSE. (5 pts)\n",
    "\n",
    "4) You should notice some overfitting. Because matrix factorization learns separate scores for each movie, a movie with very few reviews may be easily overfit. You may want to only predict ratings when you have enough information to reach a good conclusion. Recalculate the RMSE on the test data, specifically for movies with at least 50 reviews (don't retrain the models). Also report the percent of movies that are still included (after cutting those with < 50 reviews), and the percent of test ratings that are still included. (5 pts)\n",
    "\n",
    "5) Repeat steps 3 and 4 with 5-rank factorization. Display training and test RMSE. (5 pts)\n",
    "\n",
    "Hints:  \n",
    "The numpy function *nanmean* is helpful for RMSE calculation.  \n",
    "The descent algorithm will probably run for at least several minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "titles = pd.read_csv('lens1m_361M_titles.csv')\n",
    "test_X = np.load('lens1m_361M_test.npy')\n",
    "train_X = np.load('lens1m_361M_train.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Code NMF Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from numpy import dot\n",
    "\n",
    "class NonNegativeMatrixFactorization:\n",
    "    \n",
    "    def __init__(self, alpha = 0.001, epochs = 100, rank=2, stop = 0.001):\n",
    "        '''Allows user to import the desired learning rate, number of iterations/epochs and rank'''\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.rank = rank\n",
    "        self.stop = stop\n",
    "    \n",
    "    def fit(self, X):\n",
    "        '''Finds two non-negative matrices (U, V) whose product approximates the non- negative matrix X optimized using \n",
    "        gradient descent'''\n",
    "        \n",
    "        # Initialize U & V matrices\n",
    "        l = X.shape[0]\n",
    "        w = X.shape[1]\n",
    "        U = np.random.random((l,self.rank))\n",
    "        V = np.random.random((w,self.rank))\n",
    "\n",
    "        # Transpose the V matrix\n",
    "        V = V.T\n",
    "\n",
    "        # Initialize e_prev to 0.01 to avoid dividing by 0 on 1st iteration\n",
    "        e_prev = 0.01\n",
    "\n",
    "        # Iterate through each epoch until convergence criteria met\n",
    "        for epoch in xrange(self.epochs):\n",
    "\n",
    "            # Initialize error term for each epoch\n",
    "            e = 0\n",
    "\n",
    "            # Iterate through each row\n",
    "            for i in xrange(l):\n",
    "                # Iterate through each column\n",
    "                for j in xrange(w):\n",
    "\n",
    "                    # Only calculate when the cell in the X-matrix is a number greater than 0\n",
    "                    if X[i][j] > 0:\n",
    "                        eij = X[i][j] - np.dot(U[i,:], V[:,j])\n",
    "\n",
    "                        # Add squared error to the total error term\n",
    "                        e += eij**2\n",
    "\n",
    "                        for k in xrange(self.rank):\n",
    "                            dLdU = -2*eij*V[k][j]\n",
    "                            dLdV = -2*eij*U[i][k]\n",
    "                            U[i][k] = U[i][k] - self.alpha*dLdU\n",
    "                            V[k][j] = V[k][j] - self.alpha*dLdV\n",
    "\n",
    "            # Calculate percent change of total squared error changed between epochs\n",
    "            perc_change = abs(e - e_prev)/e_prev\n",
    "            e_prev = e\n",
    "\n",
    "            # If percent change in error terms between epochs is less than stopping criteria, terminate algorithm\n",
    "            if perc_change < self.stop:\n",
    "                break\n",
    "            \n",
    "        #Transpose V back\n",
    "        V = V.T\n",
    "    \n",
    "        return U, V\n",
    "\n",
    "    def predict(self, U, V):\n",
    "        '''Take dot product of U and V according to the fitted NMF model'''\n",
    "        X_pred = np.dot(U, V.T)\n",
    "        return X_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - 2-Rank Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NMF_2rank = NonNegativeMatrixFactorization(alpha = 0.001, epochs = 50, rank=2, stop = 0.001)\n",
    "\n",
    "#Factorize training matrix\n",
    "U_train, V_train = NMF_2rank.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate predicted matrix from U & V components using dot product\n",
    "X_pred = NMF_2rank.predict(U_train, V_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Rank Factorization Training RMSE:\t0.904\n",
      "2-Rank Factorization Test RMSE:\t0.923\n"
     ]
    }
   ],
   "source": [
    "#Calculate RMSE on training data\n",
    "count = 0\n",
    "sse_train = 0\n",
    "\n",
    "for i in xrange(train_X.shape[0]):\n",
    "    for j in xrange(train_X.shape[1]):\n",
    "        # Only calculate when the cell in the X-matrix is a number greater than 0\n",
    "        if train_X[i][j] > 0:\n",
    "            sse_train += (X_pred[i][j] - train_X[i][j])**2\n",
    "            count += 1\n",
    "\n",
    "# Calculate train MSE            \n",
    "mse_train = sse_train/count\n",
    "# Calculate train RMSE\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "#Calculate RMSE on test data\n",
    "count = 0\n",
    "sse_test = 0\n",
    "\n",
    "for i in xrange(test_X.shape[0]):\n",
    "    for j in xrange(test_X.shape[1]):\n",
    "        # Only calculate when the cell in the X-matrix is a number greater than 0\n",
    "        if test_X[i][j] > 0:\n",
    "            sse_test += (X_pred[i][j] - test_X[i][j])**2\n",
    "            count += 1\n",
    "\n",
    "# Calculate test MSE            \n",
    "mse_test = sse_test/count\n",
    "# Calculate test RMSE\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "print '2-Rank Factorization Training RMSE:\\t{:04.3f}'.format(rmse_train)\n",
    "print '2-Rank Factorization Test RMSE:\\t{:04.3f}'.format(rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - 2-Rank Factorization >50 Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Rank Factorization | >50 Reviews | # of Movies Included:\t1217\n",
      "2-Rank Factorization | >50 Reviews | % of Reviews Included:\t0.812\n",
      "2-Rank Factorization | >50 Reviews | Test RMSE:\t0.911\n"
     ]
    }
   ],
   "source": [
    "#Calculate RMSE on test data\n",
    "count = 0\n",
    "sse_test = 0\n",
    "total_reviews = 0\n",
    "movies_included = 0\n",
    "reviews_included = 0\n",
    "\n",
    "#Transpose matrix so rows are movies\n",
    "test_X_t = test_X.T\n",
    "X_pred_t = X_pred.T \n",
    "\n",
    "for i in xrange(test_X_t.shape[0]):\n",
    "    num_reviews = np.count_nonzero(~np.isnan(test_X_t[i]))\n",
    "    total_reviews += num_reviews\n",
    "    if num_reviews >= 50:\n",
    "        movies_included += 1\n",
    "        reviews_included += num_reviews\n",
    "        for j in xrange(test_X_t.shape[1]):\n",
    "            # Only calculate when the cell in the X-matrix is a number greater than 0\n",
    "            if test_X_t[i][j] > 0:\n",
    "                sse_test += (X_pred_t[i][j] - test_X_t[i][j])**2\n",
    "                count += 1\n",
    "\n",
    "# Calculate test MSE            \n",
    "mse_test = sse_test/count\n",
    "# Calculate test RMSE\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Calculate % of reviews included\n",
    "perc_included = reviews_included * 1.0 / total_reviews\n",
    "\n",
    "print '2-Rank Factorization | >50 Reviews | # of Movies Included:\\t{}'.format(movies_included)\n",
    "print '2-Rank Factorization | >50 Reviews | % of Reviews Included:\\t{:04.3f}'.format(perc_included)\n",
    "print '2-Rank Factorization | >50 Reviews | Test RMSE:\\t{:04.3f}'.format(rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - 5-Rank Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialize model w/ 5 ranks\n",
    "NMF_5rank = NonNegativeMatrixFactorization(alpha = 0.001, epochs = 50, rank=5, stop = 0.001)\n",
    "\n",
    "#Factorize training matrix\n",
    "U_train, V_train = NMF_5rank.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate predicted matrix from U & V components using dot product\n",
    "X_pred = NMF_5rank.predict(U_train, V_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Rank Factorization Training RMSE:\t0.851\n",
      "5-Rank Factorization Test RMSE:\t0.893\n"
     ]
    }
   ],
   "source": [
    "#Calculate RMSE on training data\n",
    "count = 0\n",
    "sse_train = 0\n",
    "\n",
    "for i in xrange(train_X.shape[0]):\n",
    "    for j in xrange(train_X.shape[1]):\n",
    "        # Only calculate when the cell in the X-matrix is a number greater than 0\n",
    "        if train_X[i][j] > 0:\n",
    "            sse_train += (X_pred[i][j] - train_X[i][j])**2\n",
    "            count += 1\n",
    "\n",
    "# Calculate train MSE            \n",
    "mse_train = sse_train/count\n",
    "# Calculate train RMSE\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "#Calculate RMSE on test data\n",
    "count = 0\n",
    "sse_test = 0\n",
    "\n",
    "for i in xrange(test_X.shape[0]):\n",
    "    for j in xrange(test_X.shape[1]):\n",
    "        # Only calculate when the cell in the X-matrix is a number greater than 0\n",
    "        if test_X[i][j] > 0:\n",
    "            sse_test += (X_pred[i][j] - test_X[i][j])**2\n",
    "            count += 1\n",
    "\n",
    "# Calculate test MSE            \n",
    "mse_test = sse_test/count\n",
    "# Calculate test RMSE\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "print '5-Rank Factorization Training RMSE:\\t{:04.3f}'.format(rmse_train)\n",
    "print '5-Rank Factorization Test RMSE:\\t{:04.3f}'.format(rmse_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
