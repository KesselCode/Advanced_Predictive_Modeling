{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">MIS 382N: Advanced Predictive Modeling</p>\n",
    "# <p style=\"text-align: center;\">Assignment 5</p>\n",
    "## <p style=\"text-align: center;\">Total points: 50 </p>\n",
    "## <p style=\"text-align: center;\">Due: Mon, November 28</p>\n",
    "\n",
    "\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. Please submit **only one** ipynb file from each group, and include the names of all the group members. Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Random Forest vs Boosting - Regression (15pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we will compare performance of different ensemble methods for regression problems: [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), [Gradient Boosting Regressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) (GBR), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor). Board game data set from DataQuest will be used (you can download data from Canvas: 'games.csv').\n",
    "\n",
    "1. (1) Load the data, (2) remove duplicate rows, (3) remove features of type string (object in pandas), and (4) replace missing values by mean of each column. Then, partition data into features (X) and the target label (y) for regression task. We want to predict the *average_rating*. Use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and testing: test_size=0.33, random_state=42. (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81312, 20)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import (RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor)\n",
    "\n",
    "games_df = pd.read_csv(\"games.csv\")\n",
    "\n",
    "games_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79463, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df = games_df.drop_duplicates()\n",
    "games_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_cols = []\n",
    "for i in range(len(games_df.dtypes)):\n",
    "    if games_df.dtypes[i] == 'O':\n",
    "        drop_cols.append(games_df.columns[i])\n",
    "games_df = games_df.drop(drop_cols,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games_df = games_df.fillna(games_df.mean())\n",
    "\n",
    "games_dfX = games_df.drop(\"average_rating\",axis=1)\n",
    "games_dfY = games_df[[\"average_rating\"]]\n",
    "X = games_dfX.as_matrix()\n",
    "Y = games_dfY.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "\n",
    "Use a [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) to predict average_rating. Find the best parameters (including *n_estimators*) using [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Report the accuracy of your model in terms of RMSE. (4pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Sean\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:645: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  best_estimator.fit(X, y, **self.fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE:  1.02463811055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.145333</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.869994</td>\n",
       "      <td>0.972578</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.870529</td>\n",
       "      <td>0.972811</td>\n",
       "      <td>0.870684</td>\n",
       "      <td>0.972463</td>\n",
       "      <td>0.868769</td>\n",
       "      <td>0.972460</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.999667</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.882311</td>\n",
       "      <td>0.979081</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883330</td>\n",
       "      <td>0.979204</td>\n",
       "      <td>0.881645</td>\n",
       "      <td>0.979309</td>\n",
       "      <td>0.881960</td>\n",
       "      <td>0.978729</td>\n",
       "      <td>0.185733</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.710000</td>\n",
       "      <td>0.057333</td>\n",
       "      <td>0.885301</td>\n",
       "      <td>0.981134</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885611</td>\n",
       "      <td>0.981058</td>\n",
       "      <td>0.885518</td>\n",
       "      <td>0.981140</td>\n",
       "      <td>0.884774</td>\n",
       "      <td>0.981203</td>\n",
       "      <td>0.105075</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       1.145333         0.020667         0.869994          0.972578   \n",
       "1       1.999667         0.038333         0.882311          0.979081   \n",
       "2       2.710000         0.057333         0.885301          0.981134   \n",
       "\n",
       "  param_n_estimators                 params  rank_test_score  \\\n",
       "0                  5   {u'n_estimators': 5}                3   \n",
       "1                 10  {u'n_estimators': 10}                2   \n",
       "2                 15  {u'n_estimators': 15}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.870529            0.972811           0.870684   \n",
       "1           0.883330            0.979204           0.881645   \n",
       "2           0.885611            0.981058           0.885518   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.972463           0.868769            0.972460      0.009177   \n",
       "1            0.979309           0.881960            0.978729      0.185733   \n",
       "2            0.981140           0.884774            0.981203      0.105075   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000943        0.000869         0.000164  \n",
       "1        0.000471        0.000731         0.000252  \n",
       "2        0.000943        0.000374         0.000060  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "RandFor = RandomForestRegressor()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)]}\n",
    "\n",
    "clf = GridSearchCV(RandFor, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Random Forest RMSE: \", np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "\n",
    "Use [Gradient Boosting Regressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) (GBR), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor) for predicting the targets. Again, find the best parameters (including *n_estimators,* and* learning_rate*), and report corresponding RMSE for each algorithm. (8pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost RMSE:  1.26376339821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.172667</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.558891</td>\n",
       "      <td>0.559193</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557174</td>\n",
       "      <td>0.559116</td>\n",
       "      <td>0.561560</td>\n",
       "      <td>0.559040</td>\n",
       "      <td>0.557938</td>\n",
       "      <td>0.559424</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.757417</td>\n",
       "      <td>0.757920</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755931</td>\n",
       "      <td>0.757992</td>\n",
       "      <td>0.760027</td>\n",
       "      <td>0.757267</td>\n",
       "      <td>0.756294</td>\n",
       "      <td>0.758502</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.000507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.569000</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.829294</td>\n",
       "      <td>0.829973</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828369</td>\n",
       "      <td>0.830177</td>\n",
       "      <td>0.831583</td>\n",
       "      <td>0.829155</td>\n",
       "      <td>0.827931</td>\n",
       "      <td>0.830587</td>\n",
       "      <td>0.054997</td>\n",
       "      <td>9.427407e-04</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.235333</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.081725</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.081346</td>\n",
       "      <td>0.081793</td>\n",
       "      <td>0.082154</td>\n",
       "      <td>0.081724</td>\n",
       "      <td>0.081675</td>\n",
       "      <td>0.081883</td>\n",
       "      <td>0.030619</td>\n",
       "      <td>1.247235e-03</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>0.155692</td>\n",
       "      <td>0.155781</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.155020</td>\n",
       "      <td>0.155766</td>\n",
       "      <td>0.156517</td>\n",
       "      <td>0.155639</td>\n",
       "      <td>0.155539</td>\n",
       "      <td>0.155937</td>\n",
       "      <td>0.060884</td>\n",
       "      <td>1.247320e-03</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.472667</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.222593</td>\n",
       "      <td>0.222702</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.221690</td>\n",
       "      <td>0.222686</td>\n",
       "      <td>0.223760</td>\n",
       "      <td>0.222492</td>\n",
       "      <td>0.222327</td>\n",
       "      <td>0.222928</td>\n",
       "      <td>0.047675</td>\n",
       "      <td>1.885594e-03</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.218667</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.008509</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>0.051123</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.016883</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.016954</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>0.016965</td>\n",
       "      <td>0.105360</td>\n",
       "      <td>1.247235e-03</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>0.025296</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.025084</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>0.025257</td>\n",
       "      <td>0.025322</td>\n",
       "      <td>0.086975</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.172667         0.003000         0.558891          0.559193   \n",
       "1       0.266667         0.005000         0.757417          0.757920   \n",
       "2       0.569000         0.007667         0.829294          0.829973   \n",
       "3       0.235333         0.004333         0.081725          0.081800   \n",
       "4       0.493333         0.006333         0.155692          0.155781   \n",
       "5       0.472667         0.008667         0.222593          0.222702   \n",
       "6       0.218667         0.003667         0.008453          0.008516   \n",
       "7       0.341000         0.005667         0.016883          0.016948   \n",
       "8       0.440000         0.007000         0.025230          0.025296   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "0                 0.1                  5   \n",
       "1                 0.1                 10   \n",
       "2                 0.1                 15   \n",
       "3                0.01                  5   \n",
       "4                0.01                 10   \n",
       "5                0.01                 15   \n",
       "6               0.001                  5   \n",
       "7               0.001                 10   \n",
       "8               0.001                 15   \n",
       "\n",
       "                                           params  rank_test_score  \\\n",
       "0     {u'n_estimators': 5, u'learning_rate': 0.1}                3   \n",
       "1    {u'n_estimators': 10, u'learning_rate': 0.1}                2   \n",
       "2    {u'n_estimators': 15, u'learning_rate': 0.1}                1   \n",
       "3    {u'n_estimators': 5, u'learning_rate': 0.01}                6   \n",
       "4   {u'n_estimators': 10, u'learning_rate': 0.01}                5   \n",
       "5   {u'n_estimators': 15, u'learning_rate': 0.01}                4   \n",
       "6   {u'n_estimators': 5, u'learning_rate': 0.001}                9   \n",
       "7  {u'n_estimators': 10, u'learning_rate': 0.001}                8   \n",
       "8  {u'n_estimators': 15, u'learning_rate': 0.001}                7   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.557174            0.559116           0.561560   \n",
       "1           0.755931            0.757992           0.760027   \n",
       "2           0.828369            0.830177           0.831583   \n",
       "3           0.081346            0.081793           0.082154   \n",
       "4           0.155020            0.155766           0.156517   \n",
       "5           0.221690            0.222686           0.223760   \n",
       "6           0.008379            0.008516           0.008476   \n",
       "7           0.016773            0.016947           0.016954   \n",
       "8           0.025084            0.025294           0.025348   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.559040           0.557938            0.559424      0.015326   \n",
       "1            0.757267           0.756294            0.758502      0.000471   \n",
       "2            0.829155           0.827931            0.830587      0.054997   \n",
       "3            0.081724           0.081675            0.081883      0.030619   \n",
       "4            0.155639           0.155539            0.155937      0.060884   \n",
       "5            0.222492           0.222327            0.222928      0.047675   \n",
       "6            0.008509           0.008503            0.008525      0.051123   \n",
       "7            0.016932           0.016922            0.016965      0.105360   \n",
       "8            0.025272           0.025257            0.025322      0.086975   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0    0.000000e+00        0.001913         0.000166  \n",
       "1    0.000000e+00        0.001851         0.000507  \n",
       "2    9.427407e-04        0.001628         0.000602  \n",
       "3    1.247235e-03        0.000332         0.000065  \n",
       "4    1.247320e-03        0.000621         0.000122  \n",
       "5    1.885594e-03        0.000866         0.000178  \n",
       "6    4.713704e-04        0.000053         0.000007  \n",
       "7    1.247235e-03        0.000079         0.000014  \n",
       "8    1.123916e-07        0.000109         0.000020  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Gradient Boost\n",
    "\n",
    "GradBoost = GradientBoostingRegressor()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)],\"learning_rate\":[10**(0-i-1) for i in range(3)]}\n",
    "\n",
    "clf = GridSearchCV(GradBoost, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Gradient Boost RMSE: \", np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "pd.DataFrame(clf.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost RMSE:  1.15089769168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.337000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.855540</td>\n",
       "      <td>0.855711</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.855731</td>\n",
       "      <td>0.855897</td>\n",
       "      <td>0.856936</td>\n",
       "      <td>0.854725</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.856512</td>\n",
       "      <td>0.033176</td>\n",
       "      <td>9.428531e-04</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.619333</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.856324</td>\n",
       "      <td>0.856556</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.856427</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.857969</td>\n",
       "      <td>0.855783</td>\n",
       "      <td>0.854576</td>\n",
       "      <td>0.857243</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>9.426845e-04</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.210667</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.857909</td>\n",
       "      <td>0.858462</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857031</td>\n",
       "      <td>0.858277</td>\n",
       "      <td>0.860419</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.856277</td>\n",
       "      <td>0.858775</td>\n",
       "      <td>0.114103</td>\n",
       "      <td>6.376979e-03</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.855369</td>\n",
       "      <td>0.855539</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.855536</td>\n",
       "      <td>0.855438</td>\n",
       "      <td>0.856951</td>\n",
       "      <td>0.854828</td>\n",
       "      <td>0.853619</td>\n",
       "      <td>0.856351</td>\n",
       "      <td>0.015513</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.738667</td>\n",
       "      <td>0.014333</td>\n",
       "      <td>0.855418</td>\n",
       "      <td>0.855591</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.855507</td>\n",
       "      <td>0.855570</td>\n",
       "      <td>0.857011</td>\n",
       "      <td>0.854734</td>\n",
       "      <td>0.853737</td>\n",
       "      <td>0.856469</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>3.299873e-03</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.893667</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.855484</td>\n",
       "      <td>0.855675</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855713</td>\n",
       "      <td>0.855794</td>\n",
       "      <td>0.857034</td>\n",
       "      <td>0.854784</td>\n",
       "      <td>0.853705</td>\n",
       "      <td>0.856446</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.302667</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.855308</td>\n",
       "      <td>0.855529</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.855287</td>\n",
       "      <td>0.855525</td>\n",
       "      <td>0.857026</td>\n",
       "      <td>0.854700</td>\n",
       "      <td>0.853611</td>\n",
       "      <td>0.856361</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.599333</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.855330</td>\n",
       "      <td>0.855624</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.855739</td>\n",
       "      <td>0.855816</td>\n",
       "      <td>0.856625</td>\n",
       "      <td>0.854687</td>\n",
       "      <td>0.853626</td>\n",
       "      <td>0.856371</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.000701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.897667</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.855354</td>\n",
       "      <td>0.855552</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.855546</td>\n",
       "      <td>0.855521</td>\n",
       "      <td>0.856777</td>\n",
       "      <td>0.854674</td>\n",
       "      <td>0.853738</td>\n",
       "      <td>0.856461</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.337000         0.006667         0.855540          0.855711   \n",
       "1       0.619333         0.011667         0.856324          0.856556   \n",
       "2       1.210667         0.020000         0.857909          0.858462   \n",
       "3       0.425000         0.006000         0.855369          0.855539   \n",
       "4       0.738667         0.014333         0.855418          0.855591   \n",
       "5       0.893667         0.016000         0.855484          0.855675   \n",
       "6       0.302667         0.005667         0.855308          0.855529   \n",
       "7       0.599333         0.011333         0.855330          0.855624   \n",
       "8       0.897667         0.016000         0.855354          0.855552   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "0                 0.1                  5   \n",
       "1                 0.1                 10   \n",
       "2                 0.1                 15   \n",
       "3                0.01                  5   \n",
       "4                0.01                 10   \n",
       "5                0.01                 15   \n",
       "6               0.001                  5   \n",
       "7               0.001                 10   \n",
       "8               0.001                 15   \n",
       "\n",
       "                                           params  rank_test_score  \\\n",
       "0     {u'n_estimators': 5, u'learning_rate': 0.1}                3   \n",
       "1    {u'n_estimators': 10, u'learning_rate': 0.1}                2   \n",
       "2    {u'n_estimators': 15, u'learning_rate': 0.1}                1   \n",
       "3    {u'n_estimators': 5, u'learning_rate': 0.01}                6   \n",
       "4   {u'n_estimators': 10, u'learning_rate': 0.01}                5   \n",
       "5   {u'n_estimators': 15, u'learning_rate': 0.01}                4   \n",
       "6   {u'n_estimators': 5, u'learning_rate': 0.001}                9   \n",
       "7  {u'n_estimators': 10, u'learning_rate': 0.001}                8   \n",
       "8  {u'n_estimators': 15, u'learning_rate': 0.001}                7   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.855731            0.855897           0.856936   \n",
       "1           0.856427            0.856643           0.857969   \n",
       "2           0.857031            0.858277           0.860419   \n",
       "3           0.855536            0.855438           0.856951   \n",
       "4           0.855507            0.855570           0.857011   \n",
       "5           0.855713            0.855794           0.857034   \n",
       "6           0.855287            0.855525           0.857026   \n",
       "7           0.855739            0.855816           0.856625   \n",
       "8           0.855546            0.855521           0.856777   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.854725           0.853952            0.856512      0.033176   \n",
       "1            0.855783           0.854576            0.857243      0.012499   \n",
       "2            0.858333           0.856277            0.858775      0.114103   \n",
       "3            0.854828           0.853619            0.856351      0.015513   \n",
       "4            0.854734           0.853737            0.856469      0.018927   \n",
       "5            0.854784           0.853705            0.856446      0.001700   \n",
       "6            0.854700           0.853611            0.856361      0.000471   \n",
       "7            0.854687           0.853626            0.856371      0.000943   \n",
       "8            0.854674           0.853738            0.856461      0.002867   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0    9.428531e-04        0.001226         0.000741  \n",
       "1    9.426845e-04        0.001387         0.000599  \n",
       "2    6.376979e-03        0.001801         0.000223  \n",
       "3    1.123916e-07        0.001365         0.000626  \n",
       "4    3.299873e-03        0.001338         0.000709  \n",
       "5    0.000000e+00        0.001369         0.000684  \n",
       "6    4.713704e-04        0.001394         0.000678  \n",
       "7    4.714827e-04        0.001258         0.000701  \n",
       "8    0.000000e+00        0.001248         0.000730  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## AdaBoost\n",
    "\n",
    "AdaBoost = AdaBoostRegressor()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)],\"learning_rate\":[10**(0-i-1) for i in range(3)]}\n",
    "\n",
    "clf = GridSearchCV(AdaBoost, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"AdaBoost RMSE: \", np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4\n",
    "\n",
    "Which model did you expect to be more accurate in predicting the targets? Why? Did your observation match this expectation? (2pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expected gradient boost to perform the best, though in actuality Random Forest has the lowest out of sample RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Random Forest vs Boosting - Classification (15 pts)\n",
    "In this question, we will compare performance of different ensemble methods for classification problems: [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) (GBDT), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier). [Spam Classification Data](https://archive.ics.uci.edu/ml/datasets/Spambase) of UCI will be used (you can download data from Canvas: 'spam_uci.csv'). Don't worry about column names. The last column represents target label, 1 if spam and zero otherwise.\n",
    "\n",
    "1. Load the data and partition it into features (X) and the target label (y) for classification task. Then, use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and testing: test_size=0.33, random_state=42. (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score)\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier)\n",
    "\n",
    "spam_df = pd.read_csv(\"spam_uci.csv\")\n",
    "\n",
    "X = spam_df.drop(\"57\",axis=1)\n",
    "y = spam_df[\"57\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "\n",
    "Use a [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to classify whether an email is spam. Find the best parameters (including *n_estimators* and *criterion*) using [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Report your testing accuracy ([accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)) and [roc_auc_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score). You will need [predict_proba](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba) for roc_auc_score. (4pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score:  0.999341672153\n",
      "Random Forest Roc_auc Score:  1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.994809</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.989300</td>\n",
       "      <td>0.999513</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.00023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.997729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.999027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0          0.024         0.004000         0.994809          0.999838   \n",
       "1          0.039         0.006667         0.997729          1.000000   \n",
       "2          0.057         0.009333         0.999027          1.000000   \n",
       "\n",
       "  param_n_estimators                 params  rank_test_score  \\\n",
       "0                  5   {u'n_estimators': 5}                3   \n",
       "1                 10  {u'n_estimators': 10}                2   \n",
       "2                 15  {u'n_estimators': 15}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.989300            0.999513           0.997079   \n",
       "1           0.997082            1.000000           0.999026   \n",
       "2           0.999027            1.000000           1.000000   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0                 1.0           0.998053                 1.0      0.003559   \n",
       "1                 1.0           0.997079                 1.0      0.000817   \n",
       "2                 1.0           0.998053                 1.0      0.000816   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000000        0.003918          0.00023  \n",
       "1        0.000471        0.000917          0.00000  \n",
       "2        0.000471        0.000795          0.00000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "RandFor = RandomForestClassifier()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)]}\n",
    "\n",
    "clf = GridSearchCV(RandFor, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba)[1].as_matrix()\n",
    "\n",
    "print \"Random Forest Accuracy Score: \", accuracy_score(y_test,y_pred)\n",
    "print \"Random Forest Roc_auc Score: \", roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "Use [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) (GBDT), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier) for the spam classification problem. Again, find the best parameters (including *n_estimators, learning_rate,* and *max_depth (GBDT only)*), and report corresponding accuracy_score and roc_auc_score on the test data for each algorithm. (8pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Decision Tree Accuracy Score:  0.998683344305\n",
      "Gradient Boosting Decision Tree Roc_auc Score:  0.998871331828\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1, u'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.265944e-03</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1, u'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414280e-03</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1, u'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.024667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.428531e-04</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01, u...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.023667</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01, u...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>1.247129e-03</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01, u...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>1.247129e-03</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>8.164374e-04</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>9.427407e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.023667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.617132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.616732</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>0.617332</td>\n",
       "      <td>0.617032</td>\n",
       "      <td>8.165347e-04</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.017000         0.001000         1.000000          1.000000   \n",
       "1        0.019000         0.000333         1.000000          1.000000   \n",
       "2        0.024333         0.001000         1.000000          1.000000   \n",
       "3        0.013000         0.000667         1.000000          1.000000   \n",
       "4        0.019333         0.000667         1.000000          1.000000   \n",
       "5        0.024333         0.001000         1.000000          1.000000   \n",
       "6        0.012667         0.000333         1.000000          1.000000   \n",
       "7        0.018333         0.001000         1.000000          1.000000   \n",
       "8        0.024667         0.000667         1.000000          1.000000   \n",
       "9        0.012667         0.001000         0.617132          0.617132   \n",
       "10       0.018333         0.000667         0.617132          0.617132   \n",
       "11       0.023667         0.001000         0.617132          0.617132   \n",
       "12       0.012667         0.000667         0.617132          0.617132   \n",
       "13       0.019333         0.000667         0.617132          0.617132   \n",
       "14       0.024000         0.000667         0.617132          0.617132   \n",
       "15       0.013333         0.000333         0.617132          0.617132   \n",
       "16       0.018000         0.001000         0.617132          0.617132   \n",
       "17       0.024333         0.001000         0.617132          0.617132   \n",
       "18       0.012667         0.000667         0.617132          0.617132   \n",
       "19       0.019000         0.000333         0.617132          0.617132   \n",
       "20       0.024333         0.001000         0.617132          0.617132   \n",
       "21       0.012667         0.000333         0.617132          0.617132   \n",
       "22       0.018667         0.000667         0.617132          0.617132   \n",
       "23       0.023667         0.000667         0.617132          0.617132   \n",
       "24       0.012333         0.001000         0.617132          0.617132   \n",
       "25       0.018667         0.000667         0.617132          0.617132   \n",
       "26       0.024000         0.000667         0.617132          0.617132   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                  0.1               3                  5   \n",
       "1                  0.1               3                 10   \n",
       "2                  0.1               3                 15   \n",
       "3                  0.1               5                  5   \n",
       "4                  0.1               5                 10   \n",
       "5                  0.1               5                 15   \n",
       "6                  0.1               7                  5   \n",
       "7                  0.1               7                 10   \n",
       "8                  0.1               7                 15   \n",
       "9                 0.01               3                  5   \n",
       "10                0.01               3                 10   \n",
       "11                0.01               3                 15   \n",
       "12                0.01               5                  5   \n",
       "13                0.01               5                 10   \n",
       "14                0.01               5                 15   \n",
       "15                0.01               7                  5   \n",
       "16                0.01               7                 10   \n",
       "17                0.01               7                 15   \n",
       "18               0.001               3                  5   \n",
       "19               0.001               3                 10   \n",
       "20               0.001               3                 15   \n",
       "21               0.001               5                  5   \n",
       "22               0.001               5                 10   \n",
       "23               0.001               5                 15   \n",
       "24               0.001               7                  5   \n",
       "25               0.001               7                 10   \n",
       "26               0.001               7                 15   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "0   {u'n_estimators': 5, u'learning_rate': 0.1, u'...                1   \n",
       "1   {u'n_estimators': 10, u'learning_rate': 0.1, u...                1   \n",
       "2   {u'n_estimators': 15, u'learning_rate': 0.1, u...                1   \n",
       "3   {u'n_estimators': 5, u'learning_rate': 0.1, u'...                1   \n",
       "4   {u'n_estimators': 10, u'learning_rate': 0.1, u...                1   \n",
       "5   {u'n_estimators': 15, u'learning_rate': 0.1, u...                1   \n",
       "6   {u'n_estimators': 5, u'learning_rate': 0.1, u'...                1   \n",
       "7   {u'n_estimators': 10, u'learning_rate': 0.1, u...                1   \n",
       "8   {u'n_estimators': 15, u'learning_rate': 0.1, u...                1   \n",
       "9   {u'n_estimators': 5, u'learning_rate': 0.01, u...               10   \n",
       "10  {u'n_estimators': 10, u'learning_rate': 0.01, ...               10   \n",
       "11  {u'n_estimators': 15, u'learning_rate': 0.01, ...               10   \n",
       "12  {u'n_estimators': 5, u'learning_rate': 0.01, u...               10   \n",
       "13  {u'n_estimators': 10, u'learning_rate': 0.01, ...               10   \n",
       "14  {u'n_estimators': 15, u'learning_rate': 0.01, ...               10   \n",
       "15  {u'n_estimators': 5, u'learning_rate': 0.01, u...               10   \n",
       "16  {u'n_estimators': 10, u'learning_rate': 0.01, ...               10   \n",
       "17  {u'n_estimators': 15, u'learning_rate': 0.01, ...               10   \n",
       "18  {u'n_estimators': 5, u'learning_rate': 0.001, ...               10   \n",
       "19  {u'n_estimators': 10, u'learning_rate': 0.001,...               10   \n",
       "20  {u'n_estimators': 15, u'learning_rate': 0.001,...               10   \n",
       "21  {u'n_estimators': 5, u'learning_rate': 0.001, ...               10   \n",
       "22  {u'n_estimators': 10, u'learning_rate': 0.001,...               10   \n",
       "23  {u'n_estimators': 15, u'learning_rate': 0.001,...               10   \n",
       "24  {u'n_estimators': 5, u'learning_rate': 0.001, ...               10   \n",
       "25  {u'n_estimators': 10, u'learning_rate': 0.001,...               10   \n",
       "26  {u'n_estimators': 15, u'learning_rate': 0.001,...               10   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0            1.000000            1.000000           1.000000   \n",
       "1            1.000000            1.000000           1.000000   \n",
       "2            1.000000            1.000000           1.000000   \n",
       "3            1.000000            1.000000           1.000000   \n",
       "4            1.000000            1.000000           1.000000   \n",
       "5            1.000000            1.000000           1.000000   \n",
       "6            1.000000            1.000000           1.000000   \n",
       "7            1.000000            1.000000           1.000000   \n",
       "8            1.000000            1.000000           1.000000   \n",
       "9            0.616732            0.617332           0.617332   \n",
       "10           0.616732            0.617332           0.617332   \n",
       "11           0.616732            0.617332           0.617332   \n",
       "12           0.616732            0.617332           0.617332   \n",
       "13           0.616732            0.617332           0.617332   \n",
       "14           0.616732            0.617332           0.617332   \n",
       "15           0.616732            0.617332           0.617332   \n",
       "16           0.616732            0.617332           0.617332   \n",
       "17           0.616732            0.617332           0.617332   \n",
       "18           0.616732            0.617332           0.617332   \n",
       "19           0.616732            0.617332           0.617332   \n",
       "20           0.616732            0.617332           0.617332   \n",
       "21           0.616732            0.617332           0.617332   \n",
       "22           0.616732            0.617332           0.617332   \n",
       "23           0.616732            0.617332           0.617332   \n",
       "24           0.616732            0.617332           0.617332   \n",
       "25           0.616732            0.617332           0.617332   \n",
       "26           0.616732            0.617332           0.617332   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0             1.000000           1.000000            1.000000  3.265944e-03   \n",
       "1             1.000000           1.000000            1.000000  1.123916e-07   \n",
       "2             1.000000           1.000000            1.000000  4.714266e-04   \n",
       "3             1.000000           1.000000            1.000000  1.414280e-03   \n",
       "4             1.000000           1.000000            1.000000  4.714266e-04   \n",
       "5             1.000000           1.000000            1.000000  4.713142e-04   \n",
       "6             1.000000           1.000000            1.000000  4.713142e-04   \n",
       "7             1.000000           1.000000            1.000000  4.714266e-04   \n",
       "8             1.000000           1.000000            1.000000  9.428531e-04   \n",
       "9             0.617032           0.617332            0.617032  4.713704e-04   \n",
       "10            0.617032           0.617332            0.617032  4.714266e-04   \n",
       "11            0.617032           0.617332            0.617032  4.714266e-04   \n",
       "12            0.617032           0.617332            0.617032  4.714827e-04   \n",
       "13            0.617032           0.617332            0.617032  1.247129e-03   \n",
       "14            0.617032           0.617332            0.617032  1.123916e-07   \n",
       "15            0.617032           0.617332            0.617032  1.247129e-03   \n",
       "16            0.617032           0.617332            0.617032  1.123916e-07   \n",
       "17            0.617032           0.617332            0.617032  4.714266e-04   \n",
       "18            0.617032           0.617332            0.617032  4.713704e-04   \n",
       "19            0.617032           0.617332            0.617032  8.164374e-04   \n",
       "20            0.617032           0.617332            0.617032  4.714266e-04   \n",
       "21            0.617032           0.617332            0.617032  4.713142e-04   \n",
       "22            0.617032           0.617332            0.617032  9.427407e-04   \n",
       "23            0.617032           0.617332            0.617032  4.713704e-04   \n",
       "24            0.617032           0.617332            0.617032  4.713704e-04   \n",
       "25            0.617032           0.617332            0.617032  4.713142e-04   \n",
       "26            0.617032           0.617332            0.617032  8.165347e-04   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0     1.123916e-07        0.000000         0.000000  \n",
       "1     4.713704e-04        0.000000         0.000000  \n",
       "2     1.123916e-07        0.000000         0.000000  \n",
       "3     4.714266e-04        0.000000         0.000000  \n",
       "4     4.714266e-04        0.000000         0.000000  \n",
       "5     1.123916e-07        0.000000         0.000000  \n",
       "6     4.713704e-04        0.000000         0.000000  \n",
       "7     1.123916e-07        0.000000         0.000000  \n",
       "8     4.714827e-04        0.000000         0.000000  \n",
       "9     1.123916e-07        0.000283         0.000142  \n",
       "10    4.713704e-04        0.000283         0.000142  \n",
       "11    0.000000e+00        0.000283         0.000142  \n",
       "12    4.714266e-04        0.000283         0.000142  \n",
       "13    4.713704e-04        0.000283         0.000142  \n",
       "14    4.713704e-04        0.000283         0.000142  \n",
       "15    4.713704e-04        0.000283         0.000142  \n",
       "16    1.123916e-07        0.000283         0.000142  \n",
       "17    1.123916e-07        0.000283         0.000142  \n",
       "18    4.714266e-04        0.000283         0.000142  \n",
       "19    4.714827e-04        0.000283         0.000142  \n",
       "20    0.000000e+00        0.000283         0.000142  \n",
       "21    4.713704e-04        0.000283         0.000142  \n",
       "22    4.713704e-04        0.000283         0.000142  \n",
       "23    4.714266e-04        0.000283         0.000142  \n",
       "24    0.000000e+00        0.000283         0.000142  \n",
       "25    4.713704e-04        0.000283         0.000142  \n",
       "26    4.714266e-04        0.000283         0.000142  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Gradient Boost\n",
    "\n",
    "GradBoost = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)],\"learning_rate\":[10**(0-i-1) for i in range(3)],\"max_depth\":[3,5,7]}\n",
    "\n",
    "clf = GridSearchCV(GradBoost, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba)[1].as_matrix()\n",
    "\n",
    "print \"Gradient Boosting Decision Tree Accuracy Score: \", accuracy_score(y_test,y_pred)\n",
    "print \"Gradient Boosting Decision Tree Roc_auc Score: \", roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting Accuracy Score:  0.998683344305\n",
      "AdaBoosting Roc_auc Score:  0.998871331828\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.699690e-03</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.165347e-04</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_estimators': 5, u'learning_rate': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'learning_rate': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_estimators': 15, u'learning_rate': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.012333         0.001000              1.0               1.0   \n",
       "1       0.012667         0.002000              1.0               1.0   \n",
       "2       0.009333         0.000333              1.0               1.0   \n",
       "3       0.008333         0.001000              1.0               1.0   \n",
       "4       0.008000         0.001000              1.0               1.0   \n",
       "5       0.009000         0.000333              1.0               1.0   \n",
       "6       0.008000         0.000667              1.0               1.0   \n",
       "7       0.007667         0.000667              1.0               1.0   \n",
       "8       0.008000         0.000667              1.0               1.0   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "0                 0.1                  5   \n",
       "1                 0.1                 10   \n",
       "2                 0.1                 15   \n",
       "3                0.01                  5   \n",
       "4                0.01                 10   \n",
       "5                0.01                 15   \n",
       "6               0.001                  5   \n",
       "7               0.001                 10   \n",
       "8               0.001                 15   \n",
       "\n",
       "                                           params  rank_test_score  \\\n",
       "0     {u'n_estimators': 5, u'learning_rate': 0.1}                1   \n",
       "1    {u'n_estimators': 10, u'learning_rate': 0.1}                1   \n",
       "2    {u'n_estimators': 15, u'learning_rate': 0.1}                1   \n",
       "3    {u'n_estimators': 5, u'learning_rate': 0.01}                1   \n",
       "4   {u'n_estimators': 10, u'learning_rate': 0.01}                1   \n",
       "5   {u'n_estimators': 15, u'learning_rate': 0.01}                1   \n",
       "6   {u'n_estimators': 5, u'learning_rate': 0.001}                1   \n",
       "7  {u'n_estimators': 10, u'learning_rate': 0.001}                1   \n",
       "8  {u'n_estimators': 15, u'learning_rate': 0.001}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0                1.0                 1.0                1.0   \n",
       "1                1.0                 1.0                1.0   \n",
       "2                1.0                 1.0                1.0   \n",
       "3                1.0                 1.0                1.0   \n",
       "4                1.0                 1.0                1.0   \n",
       "5                1.0                 1.0                1.0   \n",
       "6                1.0                 1.0                1.0   \n",
       "7                1.0                 1.0                1.0   \n",
       "8                1.0                 1.0                1.0   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0                 1.0                1.0                 1.0  4.714266e-04   \n",
       "1                 1.0                1.0                 1.0  1.699690e-03   \n",
       "2                 1.0                1.0                 1.0  4.714266e-04   \n",
       "3                 1.0                1.0                 1.0  4.714266e-04   \n",
       "4                 1.0                1.0                 1.0  0.000000e+00   \n",
       "5                 1.0                1.0                 1.0  8.165347e-04   \n",
       "6                 1.0                1.0                 1.0  1.123916e-07   \n",
       "7                 1.0                1.0                 1.0  4.714827e-04   \n",
       "8                 1.0                1.0                 1.0  0.000000e+00   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0    1.123916e-07             0.0              0.0  \n",
       "1    1.123916e-07             0.0              0.0  \n",
       "2    4.714827e-04             0.0              0.0  \n",
       "3    0.000000e+00             0.0              0.0  \n",
       "4    1.123916e-07             0.0              0.0  \n",
       "5    4.714827e-04             0.0              0.0  \n",
       "6    4.713704e-04             0.0              0.0  \n",
       "7    4.713704e-04             0.0              0.0  \n",
       "8    4.714827e-04             0.0              0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## AdaBoost\n",
    "\n",
    "AdaBoost = AdaBoostClassifier()\n",
    "\n",
    "parameters = {\"n_estimators\":[i*5 + 5 for i in range(3)],\"learning_rate\":[10**(0-i-1) for i in range(3)]}\n",
    "\n",
    "clf = GridSearchCV(AdaBoost, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba)[1].as_matrix()\n",
    "\n",
    "print \"AdaBoosting Accuracy Score: \", accuracy_score(y_test,y_pred)\n",
    "print \"AdaBoosting Roc_auc Score: \", roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4\n",
    "\n",
    "Point out one advantage and one disadvantage of Random Forest compared to GBDT (2pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantage: Random Forest can work in parallel as how one tree is built does not influence how another tree gets built. This makes it more scalable, and if the data vastly expands, Random Forest could be run on multiple machines. Also its conceptually a simpler model, making it easier to explain.\n",
    "\n",
    "Disadvantage: Random Forest is suceptable to outliers, and more trees can be formed from unimportant features (as they're chosen at random). The gradient boost decision tree, on the other hand, is robust towards outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 3 - Matrix Factorization for Rating Prediction (20pts)\n",
    "\n",
    "The movielens dataset contains 1 million movie ratings from several thousand users. We will be using *k*-rank matrix factorization to estimate this dataset as the product $X=UV^T$, where *U* and *V* have only $k$ columns.\n",
    "\n",
    "1) You can download the movielens 1M dataset from https://datahub.io/dataset/movielens, but for this problem use the data available on Canvas. It has been split into training and test sets, and converted to matrix format where the rows correspond to users and the columns to movies. Note that most of the entries are NaNs, indicating that these ratings are missing. An extra file, lens1m_361M_titles.csv, has been added so you can check out specific movies if you're curious.\n",
    "\n",
    "2) Scikit-learn is a little behind for recommender systems, and doesn't have any method to factorize matrices with missing data. Which means you get to code it! Slide 22 of the 'apa large scale learning' lecture notes has the equations for stochastic gradient descent on *U* and *V*. You will have to:\n",
    "* Set up initial guesses for the *U* and *V* matrices. I suggest small random values.\n",
    "* Find a suitable learning rate for the descent. A learning rate that is too large will probably blow up, like in HW3 problem 1.\n",
    "* Come up with a stopping policy\n",
    "* Code the descent algorithm (5 pts)\n",
    "\n",
    "3) Using your SGD algorithm, apply 2-rank matrix factorization on the filled training matrix. Calculate the RMSE of this model on the training data and on the test data (separately). The optimal score on the training data is around .86 RMSE; your version of gradient descent must go at least below .91 RMSE. (5 pts)\n",
    "\n",
    "4) You should notice some overfitting. Because matrix factorization learns separate scores for each movie, a movie with very few reviews may be easily overfit. You may want to only predict ratings when you have enough information to reach a good conclusion. Recalculate the RMSE on the test data, specifically for movies with at least 50 reviews (don't retrain the models). Also report the percent of movies that are still included (after cutting those with < 50 reviews), and the percent of test ratings that are still included. (5 pts)\n",
    "\n",
    "5) Repeat steps 3 and 4 with 5-rank factorization. Display training and test RMSE. (5 pts)\n",
    "\n",
    "Hints:  \n",
    "The numpy function *nanmean* is helpful for RMSE calculation.  \n",
    "The descent algorithm will probably run for at least several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "titles = pd.read_csv('lens1m_361M_titles.csv')\n",
    "test_X = np.load('lens1m_361M_test.npy')\n",
    "train_X = np.load('lens1m_361M_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
